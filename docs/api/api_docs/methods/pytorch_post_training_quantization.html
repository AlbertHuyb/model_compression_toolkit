

<!doctype html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Pytorch Post Training Quantization &#8212; MCT Documentation: ver 1.3.0</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/bizstyle.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <!--[if lt IE 9]>
    <script src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">MCT Documentation: ver 1.3.0</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Pytorch Post Training Quantization</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="pytorch-post-training-quantization">
<span id="ug-pytorch-post-training-quantization"></span><h1>Pytorch Post Training Quantization<a class="headerlink" href="#pytorch-post-training-quantization" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="model_compression_toolkit.pytorch_post_training_quantization">
<span class="sig-prename descclassname"><span class="pre">model_compression_toolkit.</span></span><span class="sig-name descname"><span class="pre">pytorch_post_training_quantization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">representative_data_gen</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quant_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">DEFAULTCONFIG</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fw_info</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">DEFAULT_PYTORCH_INFO</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">network_editor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gptq_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">analyze_similarity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fw_hw_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">PYTORCH_DEFAULT_MODEL</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#model_compression_toolkit.pytorch_post_training_quantization" title="Permalink to this definition">¶</a></dt>
<dd><p>Quantize a trained Pytorch module using post-training quantization. The module is quantized using a
symmetric constraint quantization thresholds (power of two).
The module is first optimized using several transformations (e.g. BatchNormalization folding to
preceding layers). Then, using a given dataset, statistics (e.g. min/max, histogram, etc.) are
being collected for each layer’s output (and input, depends on the quantization configuration).
Thresholds are then being calculated using the collected statistics and the module is quantized
(both coefficients and activations by default).
If a gptq configuration is passed, the quantized weights are optimized using gradient based post
training quantization by comparing points between the float and quantized modules, and minimizing the observed loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_module</strong> (<em>Module</em>) – Pytorch module to quantize.</p></li>
<li><p><strong>representative_data_gen</strong> (<em>Callable</em>) – Dataset used for calibration.</p></li>
<li><p><strong>n_iter</strong> (<em>int</em>) – Number of calibration iterations to run.</p></li>
<li><p><strong>quant_config</strong> (<a class="reference internal" href="../modules/quantization_config.html#model_compression_toolkit.QuantizationConfig" title="model_compression_toolkit.QuantizationConfig"><em>QuantizationConfig</em></a>) – QuantizationConfig containing parameters of how the module should be quantized. <a class="reference external" href="https://github.com/sony/model_optimization/blob/21e21c95ca25a31874a5be7af9dd2dd5da8f3a10/model_compression_toolkit/common/quantization/quantization_config.py#L154">Default configuration.</a></p></li>
<li><p><strong>fw_info</strong> (<a class="reference internal" href="../classes/FrameworkInfo.html#model_compression_toolkit.FrameworkInfo" title="model_compression_toolkit.FrameworkInfo"><em>FrameworkInfo</em></a>) – Information needed for quantization about the specific framework (e.g., kernel channels indices, groups of layers by how they should be quantized, etc.). <a class="reference external" href="https://github.com/sony/model_optimization/blob/21e21c95ca25a31874a5be7af9dd2dd5da8f3a10/model_compression_toolkit/pytorch/default_framework_info.py#L113">Default Pytorch info</a></p></li>
<li><p><strong>network_editor</strong> (<em>List</em><em>[</em><a class="reference internal" href="../modules/network_editor.html#model_compression_toolkit.network_editor.EditRule" title="model_compression_toolkit.network_editor.EditRule"><em>EditRule</em></a><em>]</em>) – List of EditRules. Each EditRule consists of a node filter and an action to change quantization settings of the filtered nodes.</p></li>
<li><p><strong>gptq_config</strong> (<a class="reference internal" href="../classes/GradientPTQConfig.html#model_compression_toolkit.GradientPTQConfig" title="model_compression_toolkit.GradientPTQConfig"><em>GradientPTQConfig</em></a>) – Configuration for using gptq (e.g. optimizer).</p></li>
<li><p><strong>analyze_similarity</strong> (<em>bool</em>) – Whether to plot similarity figures within TensorBoard (when logger is enabled) or not.</p></li>
<li><p><strong>fw_hw_model</strong> (<a class="reference internal" href="../modules/hardware_representation.html#model_compression_toolkit.hardware_representation.FrameworkHardwareModel" title="model_compression_toolkit.hardware_representation.FrameworkHardwareModel"><em>FrameworkHardwareModel</em></a>) – FrameworkHardwareModel to optimize the Keras model according to.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A quantized module and information the user may need to handle the quantized module.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Import a Pytorch module:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torchvision.models.mobilenet_v2</span> <span class="k">as</span> <span class="nn">models</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">mobilenet_v2</span><span class="p">()</span>
</pre></div>
</div>
<p>Create a random dataset generator:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">repr_datagen</span><span class="p">():</span> <span class="k">return</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">3</span><span class="p">))]</span>
</pre></div>
</div>
<p>Import mct and pass the module with the representative dataset generator to get a quantized module:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">model_compression_toolkit</span> <span class="k">as</span> <span class="nn">mct</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">quantized_module</span><span class="p">,</span> <span class="n">quantization_info</span> <span class="o">=</span> <span class="n">mct</span><span class="o">.</span><span class="n">pytorch_post_training_quantization</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">repr_datagen</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">MCT Documentation: ver 1.3.0</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Pytorch Post Training Quantization</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2022, Sony Semiconductors Israel.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.4.0.
    </div>
  </body>
</html>