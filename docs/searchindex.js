Search.setIndex({docnames:["api/api_docs/classes/DefaultDict","api/api_docs/classes/FolderImageLoader","api/api_docs/classes/FrameworkInfo","api/api_docs/classes/GradientPTQConfig","api/api_docs/index","api/api_docs/methods/get_keras_gptq_config","api/api_docs/methods/keras_post_training_quantization","api/api_docs/methods/keras_post_training_quantization_mixed_precision","api/api_docs/methods/pytorch_post_training_quantization","api/api_docs/methods/set_logger_path","api/api_docs/modules/mixed_precision_quantization_config","api/api_docs/modules/network_editor","api/api_docs/modules/quantization_config","guidelines/quickstart_keras","guidelines/quickstart_pytorch","guidelines/visualization","index"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":4,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":3,"sphinx.domains.rst":2,"sphinx.domains.std":2,sphinx:56},filenames:["api/api_docs/classes/DefaultDict.rst","api/api_docs/classes/FolderImageLoader.rst","api/api_docs/classes/FrameworkInfo.rst","api/api_docs/classes/GradientPTQConfig.rst","api/api_docs/index.rst","api/api_docs/methods/get_keras_gptq_config.rst","api/api_docs/methods/keras_post_training_quantization.rst","api/api_docs/methods/keras_post_training_quantization_mixed_precision.rst","api/api_docs/methods/pytorch_post_training_quantization.rst","api/api_docs/methods/set_logger_path.rst","api/api_docs/modules/mixed_precision_quantization_config.rst","api/api_docs/modules/network_editor.rst","api/api_docs/modules/quantization_config.rst","guidelines/quickstart_keras.rst","guidelines/quickstart_pytorch.rst","guidelines/visualization.rst","index.rst"],objects:{"model_compression_toolkit.DefaultDict":[[0,1,1,"","get"]],"model_compression_toolkit.FolderImageLoader":[[1,1,1,"","sample"]],"model_compression_toolkit.common.data_loader":[[1,2,1,"","FILETYPES"]],"model_compression_toolkit.network_editor":[[11,0,1,"","ChangeActivationQuantConfigAttr"],[11,0,1,"","ChangeActivationQuantizationMethod"],[11,0,1,"","ChangeCandidatesWeightsQuantConfigAttr"],[11,0,1,"","ChangeCandidtaesWeightsQuantizationMethod"],[11,0,1,"","ChangeFinalWeightsQuantizationMethod"],[11,0,1,"","ChangeQuantizationParamFunction"],[11,0,1,"","EditRule"],[11,0,1,"","NodeNameFilter"],[11,0,1,"","NodeNameScopeFilter"],[11,0,1,"","NodeTypeFilter"]],model_compression_toolkit:[[2,0,1,"","ChannelAxis"],[0,0,1,"","DefaultDict"],[1,0,1,"","FolderImageLoader"],[2,0,1,"","FrameworkInfo"],[3,0,1,"","GradientPTQConfig"],[10,0,1,"","KPI"],[10,0,1,"","MixedPrecisionQuantizationConfig"],[12,0,1,"","QuantizationConfig"],[12,0,1,"","QuantizationMethod"],[12,0,1,"","ThresholdSelectionMethod"],[5,3,1,"","get_keras_gptq_config"],[6,3,1,"","keras_post_training_quantization"],[7,3,1,"","keras_post_training_quantization_mixed_precision"],[8,3,1,"","pytorch_post_training_quantization"],[9,3,1,"","set_log_folder"]]},objnames:{"0":["py","class","Python class"],"1":["py","method","Python method"],"2":["py","data","Python data"],"3":["py","function","Python function"]},objtypes:{"0":"py:class","1":"py:method","2":"py:data","3":"py:function"},terms:{"0":[2,7,12,13,14,16],"05":12,"1":[2,6,7,8,13,16],"10":[1,7,13,16],"127":[1,13],"16":14,"1st":[3,5],"2":[2,3,5,7,12,13,16],"20":[13,14,15],"2021":16,"224":[6,7,8,13,14],"225":14,"229":14,"256":[13,14],"2nd":[3,5],"3":[2,5,6,7,8,13,14],"32":[10,13,14],"4":7,"406":14,"456":14,"485":14,"5":[1,5,13],"50":[13,14],"500":[6,7,8],"6":12,"7":[12,16],"75":7,"8":[7,12],"9":11,"byte":[7,10,15],"class":[1,10,11,12],"default":[0,5,6,7,8,12,15],"do":15,"enum":[2,12],"final":15,"float":[3,5,6,7,8,10,12,15],"function":[1,2,3,5,10,11,12,13,14],"import":[2,4,6,7,8,11,13,14,15],"int":[1,3,5,6,7,8,9,10,12,13],"new":[2,11],"return":[0,1,5,6,7,8,13,14],"true":[3,5,12,14],"while":[7,10],A:[1,2,6,7,8,11,13,14,16],As:15,By:15,For:[1,2,7,12,13,14,16],If:[0,2,6,7,8],In:[7,12],It:0,One:[12,15],The:[1,2,3,5,6,7,8,11,12,13,14,15],Then:[2,6,7,8,11,15],There:15,These:15,To:[1,2,5,15],about:[2,3,5,6,7,8],abov:12,absolut:12,accept:[3,5],accord:[10,12],action:[6,7,8],activ:[2,6,7,8,11,12],activation_channel_equ:12,activation_min_max_map:2,activation_n_bit:12,activation_op:2,activation_quantization_method:[11,12],activation_quantization_params_fn:11,activation_quantizer_map:2,activation_threshold_method:12,adam:5,add:2,advanc:2,affect:[7,10],after:[7,12],algorithm:14,all:[2,10,11,12,15],along:15,also:16,among:10,an:[2,4,6,7,8,11,13,14,16],analyze_similar:[6,7,8],ani:[0,2,3,13,14],api:[2,3,7],appli:11,applic:[6,7,13],ar:[2,6,7,8,13,14,15],argument:[13,14],arrai:[13,14],art:16,arxiv:16,attirbut:2,attr_nam:11,attr_valu:11,attribut:11,auto:4,avail:16,axi:2,base:[4,6,7,8,16],batch:[13,14],batch_siz:[1,13,14],batchnorm:[6,7,8],befor:1,being:[6,7,8],between:[6,7,8,10,12,15],bia:[3,5,7,10,12],bias:5,bit:[7,10,11,12],bitwidth:7,bmp:1,bool:[3,5,6,7,8,12],both:[6,7,8,15],build:16,calcul:[6,7,8],calibr:[1,6,7,8,13,14],call:[13,14,15],callabl:[0,1,2,3,5,6,7,8,10,13,14],can:[1,2,3,5,7,11,12,13,14,15,16],centercrop:14,chang:[6,7,8,11,15],changeactivationquantconfigattr:11,changeactivationquantizationmethod:11,changecandidatesweightsquantconfigattr:11,changecandidtaesweightsquantizationmethod:11,changefinalweightsquantizationmethod:11,changequantizationmethod:11,changequantizationparamfunct:11,channel:[2,6,7,8,12,15],check:11,click:15,clone:16,code:[13,14],coeffici:[2,6,7,8,10,12],cohen:16,collect:[2,6,7,8,15],com:16,common:1,compar:[6,7,8,10,15],comparison:16,compos:14,compress:14,comput:[2,10,15],compute_distance_fn:10,compute_ms:10,config:7,configur:[3,4,5,6,7,8,10,11,12,14],consist:[6,7,8],constraint:[6,7,8],contain:[1,6,7,8,10,13,14],conv2d:[2,7,10,11],correct:12,cosin:16,count_param:7,creat:[1,2,3,4,5,6,7,8,11,12,13,14],cropped_img:13,current:16,cv2:13,data:[13,14,15],data_load:1,dataset:[1,4,6,7,8,13,14,15],def:[6,7,8,13,14],default_factori:0,default_keras_info:[6,7],default_mixedprecision_config:7,default_pytorch_info:8,defaultconfig:[6,8,10,14],defaultdict:2,demonstr:14,dens:2,depend:[6,7,8],desir:[7,12],develop:16,diamant:16,dict:[0,2,11],dictionari:[0,2],differ:[7,10,12,15],dikstein:16,dir:15,directori:[1,4,9],disabl:5,displai:15,distanc:10,distance_weighting_method:10,distil:[3,16],distribut:12,diverg:[12,15],divid:2,divis:15,document:[4,7],don:2,done:15,dot:15,dror:16,dure:[3,4,5,11,12,15],e:[2,6,7,8,16],each:[1,6,7,8,11,13,14,15],easili:16,edit:[4,11],editrul:[6,7,8],enabl:[5,6,7,8,12,16],enable_activation_quant:12,enable_weights_quant:12,engin:16,equal:12,er_list:11,error:12,etc:[2,6,7,8,15],euclidean:15,evalu:10,exampl:[1,2,5,6,7,8,10,11,12,13,14],exist:[0,1,11],expect:15,experiment:[3,4,16],extens:1,factori:0,fals:[5,6,7,8,12],featur:7,few:[15,16],figur:[6,7,8],file:9,file_typ:1,filetyp:1,filter:[6,7,8],find:7,fine:5,first:[6,7,8],fold:[6,7,8],folder:[9,13,14],folderimageload:[1,4,13,14],follow:[1,2,3],format:2,framework:[2,4,6,7,8],frameworkinfo:[4,6,7,8],friendli:16,from:[1,2,3,6,7,11,12,13,14,15,16],fromarrai:14,fw_info:[6,7,8],g:[2,6,7,8],gather:15,gener:[0,4,6,7,8,13,14,15],get:[0,2,6,7,8,14],get_average_weight:10,get_keras_gptq_config:[4,5],git:16,github:16,given:[0,6,7,8],gptq:[3,4,5,6,7,8],gptq_conf:5,gptq_config:[6,7,8],gradient:[4,6,7,8,16],gradientptq:3,gradientptqc:4,gradientptqconfig:[4,6,7,8],graph:[11,15],group:[2,6,7,8],h:16,ha:[1,11,13,14],habi:16,handl:[6,7,8],hardwar:16,have:[2,13,14,15],height_tag:13,here:[7,13,14,16],histogram:[6,7,8,15],hold:2,how:[2,6,7,8,10,13,14,16],hptq:16,http:16,i:16,ilp:7,imag:[4,10,13,14,15],image_data_load:[1,13,14],img:14,in_model:[6,7],in_modul:8,includ:10,index:[2,4],indic:[2,6,7,8],inf:[10,12],info:[6,7,8,9],inform:[2,3,4,5,6,7,8],init:[4,11],initi:[0,1,3,13,14],inner:0,input:[6,7,8,10,12,13,14],input_sc:12,insert:15,instanc:[2,3,4,5,11],instans:12,instanti:[1,12],israel:16,iter:[3,5,6,7,8,13,14],its:[0,2,12,15],jen:16,jpeg:1,jpg:1,just:16,k:12,kei:0,kera:[2,3,4,10,11,16],keras_post_training_quant:[2,4,5,6,11,12,13,15],keras_post_training_quantization_mixed_precis:[4,7],kernel:[2,6,7,8,10],kernel_channels_map:2,kernel_op:2,kernel_ops_attributes_map:2,kl:[12,15],kmean:12,know:2,knowledg:[3,16],known_dict:0,kpi:7,kwarg:11,l:16,l_p:12,l_p_valu:12,lambda:1,last:2,latest:16,launch:15,layer:[2,6,7,8,10,11,15],layer_min_max_map:2,least:[1,13,14],level:9,librari:[2,10,12],limit:7,linear:12,list:[1,2,3,5,6,7,8,10,11,13,14],load:[1,13,14],loader:[13,14],log:[3,5,9,15],log_funct:[3,5],logdir:15,logger:[6,7,8,15],look:[7,12,16],loss:[3,5,6,7,8],lp:12,lut_quant:12,mae:[12,15],mai:[5,6,7,8,12,15],make:12,mani:15,map:2,match:11,math:12,mathemat:15,max:[2,6,7,8,12,13,15],maxim:7,mct:[2,4,6,7,8,11,15,16],mean:[12,13,14,15],measur:[10,15],memori:[10,15],method:[1,11,12],metric:10,min:[2,6,7,8,12,15],min_threshold:12,minim:[6,7,8,12],minimum:12,minut:16,mix:[4,10,16],mixed_precision_quantization_config:4,mixedprecisionquantizationconfig:7,mobilenet:[6,13],mobilenet_v2:[7,8,14],mobilenetv1:13,mobilenetv2:[7,14],model:[2,3,4,6,7,8,10,11,12,15],model_compression_toolkit:[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],model_optim:16,modifi:11,modul:8,more:[7,14,15],mse:[12,15],multipl:2,multiple_tensors_mse_loss:5,n_iter:[3,5,6,7,8,14],nadam:5,name:[11,15],nchw:2,ndarrai:[13,14],need:[2,6,7,8],neg:12,network:[2,11,15,16],network_editor:[4,6,7,8],netzer:16,neural:16,nhwc:2,nightli:16,no_no_quantization_op:2,no_quantization_op:2,noclip:12,node:[6,7,8,11,15],node_nam:11,node_name_scop:11,node_typ:11,nodenamefilt:11,nodenamescopefilt:11,nodetypefilt:11,nois:12,non:12,none:[0,3,5,6,7,8,10,11],norm:[12,15],normal:[13,14],note:[7,10],notic:[7,13,14],now:[7,15],np:[6,7,8,10,13],np_to_pil:14,num_of_imag:10,number:[1,3,5,6,7,8,10,12,13,14],numpi:[6,7,8,13,14],o:16,object:[1,2,5,7,10,11,13,14],observ:[6,7,8,15],occur:12,offset_height:13,offset_width:13,one:[1,5,12,13,14],onli:[1,2,7,10],open:16,oper:2,optim:[2,3,4,5,6,7,8,14,16],optimizerv2:5,option:[4,7],order:[5,7,12],origin:15,other:5,our:7,out:2,outlier:[12,14],output:[2,6,7,8,12,14,15],output_channel_index:2,p:12,packag:16,page:4,pair:15,param:11,paramet:[0,1,2,3,5,6,7,8,9,10,11,12],pass:[0,1,2,5,6,7,8,11,12],path:[1,9,13,14,15],per:[2,7,12,15],peretz:16,perform:10,phase:15,pil:14,pip:16,pleas:[7,16],plot:[6,7,8,15],png:1,point:[6,7,8,15],possibl:[7,10,12],post:[3,4,13,14,16],power:[6,7,8,12],power_of_two:12,preced:[6,7,8],precis:[4,10,16],preprint:16,preprocess:[1,13,14],present:0,pretrain:14,process:[1,3,4,5,10,11,12,15],product:15,project:16,provid:15,ptq:[1,4],purpos:[13,14],py:16,pypi:16,python:16,pytorch:[4,16],pytorch_post_training_quant:[4,8,14],qc:[10,12],quant_config:[6,7,8],quantifi:15,quantiz:[2,3,4,5,10,11,12,13,14,15,16],quantization_config:[4,14],quantization_info:[6,7,8,13,14],quantizationconfig:[6,7,8,10],quantizationmethod:2,quantized_model:[6,7,13,14],quantized_modul:8,quick:16,r:16,random:[6,7,8],randomli:1,rang:2,ratio:12,recomput:12,relat:2,releas:16,relu:[2,12],relu_unbound_correct:12,remov:[12,14],repr_datagen:[6,7,8],repres:[1,4,6,7,8,10,11,13,14,15],representative_data_gen:[6,7,8,13,14],request:0,requir:15,research:16,reshap:2,resiz:[13,14],resize_scal:13,resize_sid:13,resized_img:13,resourc:[10,15],respectivli:2,retriev:1,round:13,rule:11,run:[5,6,7,8,13,14,15],s:[2,6,7,8,10,11,13,14],sampl:[1,14,15],save:[2,9],scalar:15,scale:12,score:12,search:[4,7,10],second:[13,14],see:16,seen:15,select:[2,12],semiconductor:16,sensit:10,set:[2,5,6,7,8,9,13,14,15],set_log_fold:[9,15],setup:16,sever:[6,7,8,15],shape:[13,14],shift:12,shift_negative_activation_correct:12,shift_negative_ratio:12,shift_negative_threshold_recalcul:12,should:[2,3,5,6,7,8,10,12,13,14,15],show:[13,14,15],signal:12,similar:[6,7,8,12,16],size:[7,13,14],softmax:2,solver:7,some:15,soni:16,sourc:16,specif:[1,2,6,7,8,11,14,15],sphinx:4,squar:12,stabl:16,stage:15,start:16,state:16,statist:[2,6,7,8,15],std:[13,14],str:[1,2,9],string:11,student:3,support:[7,10],symetr:12,symmetr:[6,7,8,12],t:2,tab:15,tabl:12,tag:15,take:[7,16],target:7,target_kpi:7,teacher:3,tensor:[3,5,10,12,13,14,15],tensorboard:[6,7,8,16],tensorflow:[2,5,6,7,11,13,16],test:16,tf:[2,5],than:12,thei:[2,6,7,8],them:[1,15],thi:[4,7,10,14,16],three:2,threshold:[6,7,8,12,14],thu:15,time:[1,2],toolkit:14,torch:16,torchvis:[8,14],totensor:14,train:[3,4,5,13,14,16],train_bia:[3,5],transform:[6,7,8,14],transpos:2,tune:5,tupl:[2,11],tutori:[14,16],two:[6,7,8,10,12,13,14,15],type:[0,11],ui:15,unbound:12,under:15,uniform:12,unlik:10,unstabl:16,up:[12,15],updat:[3,5],us:[0,1,2,3,4,5,6,7,8,10,11,12,13,14,15,16],user:[6,7,8],v:16,valu:[0,2,7,10,11,12],variou:15,vector:15,verbos:9,version:16,view:15,visit:16,visual:16,wa:0,wai:[15,16],want:2,we:[2,7,11,13,14,15],weight:[2,6,7,8,10,11,12],weights_bias_correct:12,weights_memori:[7,10],weights_n_bit:[7,10,11,12],weights_per_channel_threshold:12,weights_quantization_method:[11,12],weights_quantization_params_fn:11,weights_quantizer_map:2,weights_threshold_method:12,were:15,when:[0,1,2,4,5,6,7,8,10,12],where:[11,13,14,15],whether:[3,5,6,7,8,12],which:[3,11,12,13,14],width:[7,10],width_tag:13,wight:11,within:[6,7,8,16],without:[13,14],work:16,would:15,wrap:[0,2,4,10,12],writer:15,x:[1,13,14],you:[15,16],your:4,z:[12,14],z_threshold:[12,14]},titles:["DefaultDict Class","Folder Image Loader API","FrameworkInfo Class","GradientPTQConfig Class","API Docs","Get GradientPTQConfig for Keras Models","Keras Post Training Quantization","Keras Post Training Mixed Precision Quantization (Experimental)","Pytorch Post Training Quantization","Enable a Logger","mixed_precision_quantization_config Module","network_editor Module","quantization_config Module","MCT Quickstart Guideline for Keras models","MCT Quickstart Guideline for Pytorch models","Visualization within TensorBoard","Model Compression Toolkit User Guide"],titleterms:{"class":[0,2,3,4],"default":1,"function":4,action:11,api:[1,4,16],channelaxi:2,comparison:15,compress:16,cosin:15,defaultdict:0,doc:4,document:16,editrul:11,enabl:9,experiment:7,featur:16,file:1,filter:11,folder:1,frameworkinfo:2,get:5,gradientptqconfig:[3,5],guid:16,guidelin:[13,14],imag:1,indic:4,instal:16,kera:[5,6,7,13],kpi:10,loader:1,logger:9,mct:[13,14],mix:7,mixed_precision_quantization_config:10,mixedprecisionquantizationconfig:10,model:[5,13,14,16],modul:[4,10,11,12],network_editor:11,overview:16,post:[6,7,8],precis:7,pytorch:[8,14],quantiz:[6,7,8],quantization_config:12,quantizationconfig:12,quantizationmethod:12,quickstart:[13,14,16],refer:16,scan:1,similar:15,support:16,tabl:4,tensorboard:15,thresholdselectionmethod:12,toolkit:16,train:[6,7,8],type:1,user:16,visual:15,within:15}})